{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# NFL 2018 Defense Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#explore libraries\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import prep_plays\n",
    "import prep_season\n",
    "plt.rc(\"figure\", figsize=(12, 7))\n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model libraries\n",
    "import wrangle_plays_data\n",
    "import prep_nfl\n",
    "import wrangle_nfl\n",
    "import MVP\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Acquire "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- We acquired the data from kaggle.com as several .csv's but the data itself is provided by nextgenstats.nfl.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nfl = pd.read_csv('plays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nfl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nfl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nfl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nfl.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_cols = nfl.columns[[(nfl[col].dtype == 'int64') | (nfl[col].dtype == 'float64') for col in nfl.columns]]\n",
    "for col in num_cols:\n",
    "    plt.hist(nfl[col])\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Takeaways:**\n",
    "- There are some null values listed that will need some investigation\n",
    "- More plays are being ran in the second and fourth quarter\n",
    "- Less plays are being ran as the down gets greater\n",
    "- Yards to go is skewed right(makes sense)\n",
    "    - Less likely to lose yards than gain\n",
    "- Most plays begin between home 20 and away 20\n",
    "    - Hard to pin your opponent inside 20 for kickoff or punt\n",
    "- Defenders in the box is a normal distribution\n",
    "- Number of pass  rushers is a normal distribution\n",
    "- Scores are skewed right\n",
    "- Play result is skewed right slightly\n",
    "- epa is fairly normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Create a function that will acquire the plays.csv\n",
    "- Keep only the useful columns that can help us determine the success of a defense(whether a pass was completed or not)\n",
    "    - `playDescription`, `quarter`, `down`, `yardsToGo`, `possessionTeam`, `offenseFormation`, `personnelO`, `defendersInTheBox`, `numberOfPassRushers`, `personnelD`, `typeDropback`, `gameClock`, `absoluteYardlineNumber`, `epa`, `playType`, `passResult`, `playResult`\n",
    "- Create a new column called `pass_stopped` \n",
    "    - Will change completion into 0\n",
    "    - Will change incomplete and interception into 1\n",
    "- Filter out data that is not a pass play(no fake punts, fake field goals, etc)\n",
    "- Create new columns that extract positions from offensive personnel\n",
    "    - RB, TE, WR\n",
    "- Create new columns that extract positions from defensive personnel\n",
    "    - DL, LB, DB\n",
    "- Rename `typeDropback` to `QB_under_pressure` and change values into normal or scramble\n",
    "- Rename `passResult` into `pass_stopped`\n",
    "- Create formations out of personnel on the field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train, validate, test = prep_plays.explore_plays_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alpha = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Does the offense formation matter? i.e. (is a certain offensive formation harder to defend?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between offensive formation and pass stopped\n",
    "- $H_a$: There is a dependence between offensive formation and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.offenseFormation, train.pass_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chi2, p, degf, expected = stats.chi2_contingency(observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"offenseFormation\", hue=\"pass_stopped\", kind=\"count\", data=train, height=8, aspect=2)._legend.remove()\n",
    "plt.title('Do certain offensive formations have more more passes stopped than others?', size = 30)\n",
    "plt.xlabel('Offensive Formation', size = 16)\n",
    "plt.ylabel('Count', size = 20)\n",
    "plt.legend(labels = ('Pass Completed', 'Pass Stopped'), loc='center right', frameon=False, fontsize='x-large')\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6], ['Shotgun', 'Empty', 'Singleback', 'I Formation', 'Pistol', 'Jumbo', 'Wildcat'], size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Takeaways:**\n",
    "- There does not seem to be a certain formation that will have there pass stopped more than others\n",
    "- After a statistical test, we can safely say that there is not dependence on stopping the play and the formation the offense is lined up in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.groupby('offenseFormation').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[train.pass_stopped ==1].groupby('offenseFormation').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stoped dependent on Down?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between down and pass stopped\n",
    "- $H_a$: There is a dependence between down and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.down, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='down', y='pass_stopped').set(ylim=(0, .55))\n",
    "plt.xlabel('Down')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "plt.title(\"Are Passes Stopped dependent on Down?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Takeaway:**\n",
    "- There is a dependence between a pass being stopped and what down it is.\n",
    "- more passes are stopped on 3rd down with 4th down right behind it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.groupby('down').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[train.pass_stopped ==1].groupby('down').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are EPA values dramatically different for passes stopped vs. passes completed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: The EPA value is the same for passes completed and passes stopped\n",
    "- $H_a$: The EPA value is different for passes completed and passes stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pass_completed = train[train.pass_stopped == 0]\n",
    "pass_not_completed = train[train.pass_stopped == 1]\n",
    "\n",
    "t, p = stats.ttest_ind(pass_completed.epa, pass_not_completed.epa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(10, 6))\n",
    "sns.violinplot(train.pass_stopped, train.epa)\n",
    "plt.xlabel('')\n",
    "plt.xticks([0,1], ['Pass Completed', 'Pass Stopped'])\n",
    "plt.yticks(size = 24)\n",
    "plt.ylabel('EPA')\n",
    "plt.title(\"Are Passes Stopped dependent on EPA?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"The EPA mean for passes completed is {pass_completed.epa.mean()}.\")\n",
    "print(f\"The EPA minimum for passes completed is {pass_completed.epa.min()}.\")\n",
    "print(f\"The EPA max for passes completed is {pass_completed.epa.max()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"The EPA mean for passes stopped is {pass_not_completed.epa.mean()}.\")\n",
    "print(f\"The EPA minimum for passes stopped is {pass_not_completed.epa.min()}.\")\n",
    "print(f\"The EPA max for passes stopped is {pass_not_completed.epa.max()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Takeaways:**\n",
    "- On average the EPA is negative for passes stopped and the EPA is positive for passes completed\n",
    "- The pass is usually stopped when the EPA is negative but not always.\n",
    "- If the EPA is above 2.5 then it almost guarantees that the pass will be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on QB pressure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between QB pressure and pass stopped\n",
    "- $H_a$: There is a dependence between QB pressure and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.QB_under_pressure, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='QB_under_pressure', y='pass_stopped').set(ylim=(0, .55))\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "plt.xticks([0,1], ['No Pressure', 'Pressure Applied'])\n",
    "plt.title(\"Are Passes Stopped dependent on Pressure Applied to QB?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.groupby('QB_under_pressure').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[train.pass_stopped ==1].groupby('QB_under_pressure').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on how many Defenders are in the Box?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between defenders in the box and pass stopped\n",
    "- $H_a$: There is a dependence between defenders in the box and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.defendersInTheBox, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='defendersInTheBox', y='pass_stopped').set(ylim=(0, .55))\n",
    "plt.xlabel('Defenders in the Box')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "plt.xticks([0,1,2,3,4,5,6,7,8,9], [1,2,3,4,5,6,7,8,9,10])\n",
    "plt.title(\"Are Passes Stopped dependent on the number of Defenders in the Box?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.groupby('defendersInTheBox').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[train.pass_stopped ==1].groupby('defendersInTheBox').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on how many DL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between DL and pass stopped\n",
    "- $H_a$: There is a dependence between DL and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.DL, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='DL', y='pass_stopped').set(ylim=(0, .55))\n",
    "plt.xlabel('Number of DL')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "# plt.xticks([0,1,2,3,4,5,6,7,8,9], [1,2,3,4,5,6,7,8,9,10])\n",
    "plt.title(\"Are Passes Stopped dependent on DL count?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.groupby('DL').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[train.pass_stopped ==1].groupby('DL').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on how many LB?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between LB and pass stopped\n",
    "- $H_a$: There is a dependence between LB and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.LB, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='LB', y='pass_stopped').set(ylim=(0, .55))\n",
    "plt.xlabel('Number of LB')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "# plt.xticks([0,1,2,3,4,5,6,7,8,9], [1,2,3,4,5,6,7,8,9,10])\n",
    "plt.title(\"Are Passes Stopped dependent on LB count?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on how many DB?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between DB and pass stopped\n",
    "- $H_a$: There is a dependence between DB and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.DB, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='DB', y='pass_stopped').set(ylim=(0, .55))\n",
    "plt.xlabel('Number of DB')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "# plt.xticks([0,1,2,3,4,5,6,7,8,9], [1,2,3,4,5,6,7,8,9,10])\n",
    "plt.title(\"Are Passes Stopped Dependent on DB count?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.groupby('DB').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train[train.pass_stopped ==1].groupby('DB').pass_stopped.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on how defensive formation(Nickel)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between Nickel formation and pass stopped\n",
    "- $H_a$: There is a dependence between Nickel formation and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.nickel, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='nickel', y='pass_stopped').set(ylim=(0, .40))\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "plt.title(\"Is the Nickle Formation better at stopping the pass than other formations?\")\n",
    "plt.xticks([0,1], ['Other Formation', 'Nickle Formation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on how defensive formation(Dime)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "- $H_0$: There is no dependence between Dime formation and pass stopped\n",
    "- $H_a$: There is a dependence between Dime formation and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.dime, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='dime', y='pass_stopped').set(ylim=(0, .40))\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "plt.title(\"Is the Dime Formation better at stopping the pass than other formations?\")\n",
    "plt.xticks([0,1], ['Other Formation', 'Dime Formation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on how defensive formation(4-3)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between 4-3 formation and pass stopped\n",
    "- $H_a$: There is a dependence between 4-3 formation and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.four_three, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='four_three', y='pass_stopped').set(ylim=(0, .40))\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "plt.title(\"Is the 4-3 Formation better at stopping the pass than other formations?\")\n",
    "plt.xticks([0,1], ['Other Formation', '4-3 Formation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Are passes stopped dependent on how defensive formation(3-4)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- $H_0$: There is no dependence between 3-4 formation and pass stopped\n",
    "- $H_a$: There is a dependence between 3-4 formation and pass stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observed = pd.crosstab(train.three_four, train.pass_stopped)\n",
    "\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"We reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=train,x='three_four', y='pass_stopped').set(ylim=(0, .40))\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Pass Stopped %')\n",
    "plt.title(\"Is the 3-4 Formation better at stopping the pass than other formations?\")\n",
    "plt.xticks([0,1], ['Other Formation', '3-4 Formation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## What makes a defense good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('season.csv')\n",
    "defensedf = df[df[\"position\"].isin([\"CB\", \"OLB\", \"SS\",\"FS\",\"ILB\",\"DE\",\"LB\",\"MLB\",\"S\",\"DT\",\"DL\",\"DB\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(13,7)\n",
    "posdf = defensedf.groupby('position')['event'].sum().reset_index()\n",
    "#pos20 = posdf.sort_values(by='event', ascending=False)\n",
    "posdf = posdf.sort_values(by=['event'], ascending =False)\n",
    "#plt.grid()\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.barplot(data=posdf, x='position', y= 'event', palette='mako')\n",
    "sns.color_palette('Blues')\n",
    "plt.title('Position and Incompletions', fontsize=13)\n",
    "plt.xlabel('Defensive Position',fontsize=13)\n",
    "plt.ylabel('Incomplete Passes',fontsize=13)\n",
    "posdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cbdf = defensedf[defensedf['position'] == 'CB']\n",
    "olbdf = defensedf[defensedf['position'] == 'OLB']\n",
    "ssdf = defensedf[defensedf['position'] == 'SS']\n",
    "fsdf = defensedf[defensedf['position'] == 'FS']\n",
    "ilbdf = defensedf[defensedf['position'] == 'ILB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Cornerback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prep_season.get_viz(cbdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Outside Linebacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prep_season.get_viz(olbdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Strong Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prep_season.get_viz(ssdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Free Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prep_season.get_viz(fsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Inside Linebacker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Defensive Position Takeaways - Top 5 Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep_season.get_viz(ilbdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### CORNERBACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Ages:**\n",
    "-    23, 25, 27, 26, 28\n",
    "\n",
    "**Colleges:**\n",
    "-    Ohio state, Florida state, lsu, Alabama, Florida\n",
    "\n",
    "**Height:**\n",
    "-    71\", 72\", 73\", 70\", 69\"\n",
    "\n",
    "**Weight:**\n",
    "-    190lbs, 196lbs, 195lbs, 192lbs, 185lbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### OUTSIDE LINEBACKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Ages:**\n",
    "- 25, 27, 23, 28, 26\n",
    "\n",
    "**College:**\n",
    "- Georgia, Florida state, Southern California, Kentucky\n",
    "\n",
    "**Height:**\n",
    "- 75\", 73\", 76\", 74\", 77\"\n",
    "\n",
    "**Weight:**\n",
    "- 250lbs, 255lbs, 265lbs, 240lbs, 235lbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### STRONG SAFETY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Ages:**\n",
    "- 27, 24, 26, 30, 25\n",
    "\n",
    "**College:**\n",
    "- Ohio state, boston college, lsu, Georgia, Texas \n",
    "\n",
    "**Height:**\n",
    "- 72\",71\",73\",74\",70\"\n",
    "\n",
    "**Weight:**\n",
    "- 215lbs, 210lbs, 202lbs, 195lbs, 212lbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### FREE SAFETY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Ages:**\n",
    "- 27, 25, 26, 22, 24\n",
    "\n",
    "**College:**\n",
    "- Utah, Rutgers, Alabama, South Carolina, ohio state\n",
    "\n",
    "**Height:**\n",
    "- 73\", 71\", 72\", 70\", 74\"\n",
    "\n",
    "**Weight:**\n",
    "- 205lbs, 195lbs, 212lbs, 202lbs, 14lbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### INSIDE LINEBACKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Ages:**\n",
    "- 23, 28, 26, 24, 29\n",
    "\n",
    "**College:**\n",
    "- Kentucky, Alabama, Washington, Florida state,stanford\n",
    "\n",
    "**Height:**\n",
    "- 73\", 72\", 74\", 75\", 76\"\n",
    "\n",
    "**Weight:**\n",
    "- 250lbs, 232lbs, 230lbs, 245lbs, 235lbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Who are the top defenders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prep_season.top_defenders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Ready For Use\n"
     ]
    }
   ],
   "source": [
    " df = prep_nfl.get_nfl_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_validate, y_validate, X_test, y_test = wrangle_nfl.train_validate_test(df)\n",
    "X_train_scaled, X_validate_scaled, X_test_scaled = wrangle_nfl.min_max_scale(X_train, X_validate, X_test)\n",
    "X_train_scaled, X_validate_scaled, X_test_scaled = wrangle_nfl.add_clusters(X_train_scaled,\n",
    "                                                                            X_validate_scaled, X_test_scaled,\n",
    "                                                                            X_train,X_validate, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled2 = X_train_scaled[['epa', 'time_since_last_x', 'x', 'a', 'yardsToGo', 'down',\n",
    "                              'absoluteYardlineNumber', 's', 'y', 'force_per_second',\n",
    "                              'QB_under_pressure', 'closest_dist', 'closest_x', 'closest_y']]\n",
    "X_validate_scaled2 = X_validate_scaled[['epa', 'time_since_last_x', 'x', 'a', 'yardsToGo', 'down',\n",
    "                              'absoluteYardlineNumber', 's', 'y', 'force_per_second',\n",
    "                              'QB_under_pressure', 'closest_dist', 'closest_x', 'closest_y']]\n",
    "X_test_scaled2 = X_test_scaled[['epa', 'time_since_last_x', 'x', 'a', 'yardsToGo', 'down',\n",
    "                              'absoluteYardlineNumber', 's', 'y', 'force_per_second',\n",
    "                                  'QB_under_pressure', 'closest_dist', 'closest_x', 'closest_y']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after running through several learning rates \n",
    "# from .0001 up to 100, 1 is the best parameter\n",
    "boost_params = {'learning_rate': [1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9639286622045242\n"
     ]
    }
   ],
   "source": [
    "ml = GridSearchCV(GradientBoostingClassifier(), boost_params, cv=5)\n",
    "ml.fit(X_train_scaled, y_train)\n",
    "print(ml.score(X_train_scaled, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ml.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58706</td>\n",
       "      <td>1918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1488</td>\n",
       "      <td>32312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  58706   1918\n",
       "1   1488  32312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.975280</td>\n",
       "      <td>0.943967</td>\n",
       "      <td>0.963929</td>\n",
       "      <td>0.959624</td>\n",
       "      <td>0.964071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.968362</td>\n",
       "      <td>0.955976</td>\n",
       "      <td>0.963929</td>\n",
       "      <td>0.962169</td>\n",
       "      <td>0.963929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.971809</td>\n",
       "      <td>0.949934</td>\n",
       "      <td>0.963929</td>\n",
       "      <td>0.960871</td>\n",
       "      <td>0.963978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>60624.000000</td>\n",
       "      <td>33800.000000</td>\n",
       "      <td>0.963929</td>\n",
       "      <td>94424.000000</td>\n",
       "      <td>94424.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy     macro avg  weighted avg\n",
       "precision      0.975280      0.943967  0.963929      0.959624      0.964071\n",
       "recall         0.968362      0.955976  0.963929      0.962169      0.963929\n",
       "f1-score       0.971809      0.949934  0.963929      0.960871      0.963978\n",
       "support    60624.000000  33800.000000  0.963929  94424.000000  94424.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.19879885e-03, 2.17857313e-03, 3.54018907e-03, 1.81732158e-04,\n",
       "       1.38240377e-06, 1.02419023e-04, 6.82124691e-05, 4.46578918e-03,\n",
       "       3.00905972e-05, 3.60959879e-05, 4.02455030e-05, 6.19442420e-03,\n",
       "       1.38592370e-03, 0.00000000e+00, 4.19811170e-04, 3.41087174e-03,\n",
       "       2.89364890e-02, 5.44126922e-03, 1.43109606e-03, 2.12072609e-03,\n",
       "       2.41396771e-03, 1.49230705e-03, 6.52409602e-03, 7.37556548e-01,\n",
       "       2.93184416e-04, 4.04319904e-04, 4.29781497e-04, 1.03963078e-03,\n",
       "       4.40366367e-04, 0.00000000e+00, 2.89850660e-05, 7.47170869e-05,\n",
       "       3.49907619e-05, 1.90236049e-05, 1.60151620e-04, 7.99556150e-05,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.62316058e-01, 1.17806346e-02, 7.69125676e-03,\n",
       "       4.86515134e-04, 7.55009803e-04, 7.88997646e-04, 5.36246069e-06])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ml.best_estimator_.feature_importances_\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X_train_scaled.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"figure\", figsize=(12, 12))\n",
    "plt.barh(range(n_features), ml.best_estimator_.feature_importances_, align = 'center')\n",
    "plt.yticks(np.arange(n_features).sort_values(), X_train_scaled.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953814708125053\n"
     ]
    }
   ],
   "source": [
    "ml2 = GridSearchCV(GradientBoostingClassifier(), boost_params, cv=5)\n",
    "ml2.fit(X_train_scaled2, y_train)\n",
    "print(ml2.score(X_train_scaled2, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TRAIN creating object\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
    "                     weights='uniform')\n",
    "\n",
    "y_pred = knn.predict(X_train_scaled)\n",
    "\n",
    "y_pred_proba = knn.predict_proba(X_train_scaled)\n",
    "\n",
    "print('>>>>>>>>>> Accuracy of KNN classifier on TRAIN set: {:.2f}'\n",
    "     .format(knn.score(X_train_scaled, y_train)))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SCALED creating the object\n",
    "logit = LogisticRegression(C=1, class_weight={0:1, 1:99}, random_state=123, intercept_scaling=1, solver='lbfgs')\n",
    "\n",
    "# fit the model\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "LogisticRegression(C=1, class_weight={0: 1, 1: 99}, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)\n",
    "\n",
    "y_pred = logit.predict(X_train_scaled)\n",
    "\n",
    "y_pred_proba = logit.predict_proba(X_train_scaled)\n",
    "\n",
    "print('>>>>>>>>>> Accuracy of Logistic Regression classifier on TRAIN set: {:.2f}'\n",
    "     .format(logit.score(X_train_scaled, y_train)))\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SVM Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(probability = True, random_state = 123)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_train)\n",
    "y_pred_proba = svm.predict_proba(X_train)\n",
    "y_pred_proba[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "      .format(svm.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f6ea59e27b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m rf = RandomForestClassifier(bootstrap=True, \n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=8,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=15, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e187ed6bf38a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train_scaled)\n",
    "\n",
    "rf.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9545353455123113\n"
     ]
    }
   ],
   "source": [
    "print(ml.score(X_validate_scaled, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = ml.predict(X_validate_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38804</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1612</td>\n",
       "      <td>21284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  38804   1250\n",
       "1   1612  21284"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y_pred_val, y_validate))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.968792</td>\n",
       "      <td>0.929595</td>\n",
       "      <td>0.954535</td>\n",
       "      <td>0.949193</td>\n",
       "      <td>0.954761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.960115</td>\n",
       "      <td>0.944528</td>\n",
       "      <td>0.954535</td>\n",
       "      <td>0.952322</td>\n",
       "      <td>0.954535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.964434</td>\n",
       "      <td>0.937002</td>\n",
       "      <td>0.954535</td>\n",
       "      <td>0.950718</td>\n",
       "      <td>0.954614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>40416.000000</td>\n",
       "      <td>22534.000000</td>\n",
       "      <td>0.954535</td>\n",
       "      <td>62950.000000</td>\n",
       "      <td>62950.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy     macro avg  weighted avg\n",
       "precision      0.968792      0.929595  0.954535      0.949193      0.954761\n",
       "recall         0.960115      0.944528  0.954535      0.952322      0.954535\n",
       "f1-score       0.964434      0.937002  0.954535      0.950718      0.954614\n",
       "support    40416.000000  22534.000000  0.954535  62950.000000  62950.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report = pd.DataFrame(classification_report(y_validate, y_pred_val, output_dict=True))\n",
    "class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_validate_scaled)\n",
    "\n",
    "y_pred_proba = knn.predict_proba(X_validate_scaled)\n",
    "\n",
    "print('>>>>>>>>>> Accuracy of KNN classifier on VALIDATE set: {:.2f}'\n",
    "      .format(knn.score(X_validate_scaled, y_validate)))\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_validate, y_pred))\n",
    "\n",
    "report = pd.DataFrame(classification_report(y_validate, y_pred, output_dict=True))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('>>>>>>>>>> Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_validate_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_validate_scaled, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_validate, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(y_validate, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Ready For Use\n",
      "---------------------------- Train -----------------------------------\n",
      "Accuracy of random forest classifier on training set: 0.95\n",
      "Training Data Matrix\n",
      "[[57801  2823]\n",
      " [ 1801 31999]]\n",
      "Training Data Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     60624\n",
      "           1       0.92      0.95      0.93     33800\n",
      "\n",
      "    accuracy                           0.95     94424\n",
      "   macro avg       0.94      0.95      0.95     94424\n",
      "weighted avg       0.95      0.95      0.95     94424\n",
      "\n",
      "---------------------------- Validate -------------------------------\n",
      "Accuracy of random forest classifier on validate set: 0.93\n",
      "Validate Data Matrix\n",
      "[[37803  2613]\n",
      " [ 1723 20811]]\n",
      "Validate Data Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95     40416\n",
      "           1       0.89      0.92      0.91     22534\n",
      "\n",
      "    accuracy                           0.93     62950\n",
      "   macro avg       0.92      0.93      0.93     62950\n",
      "weighted avg       0.93      0.93      0.93     62950\n",
      "\n",
      "---------------------------- Test -----------------------------------\n",
      "Accuracy of random forest classifier on test set: 0.93\n",
      "Test Data Matrix\n",
      "[[40472  2832]\n",
      " [ 1925 22218]]\n",
      "Test Data Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94     43304\n",
      "           1       0.89      0.92      0.90     24143\n",
      "\n",
      "    accuracy                           0.93     67447\n",
      "   macro avg       0.92      0.93      0.92     67447\n",
      "weighted avg       0.93      0.93      0.93     67447\n",
      "\n",
      "--------------------- Important Features ----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<function MVP.MVP()>,\n",
       "                         importance\n",
       " epa                       0.634587\n",
       " closest_dist              0.154487\n",
       " closest_x                 0.035822\n",
       " time_since_last_x         0.029932\n",
       " closest_y                 0.026328\n",
       " down                      0.019574\n",
       " yardsToGo                 0.018122\n",
       " x                         0.015954\n",
       " s                         0.014934\n",
       " absoluteYardlineNumber    0.013214\n",
       " force_per_second          0.011466\n",
       " a                         0.010890\n",
       " y                         0.007996\n",
       " QB_under_pressure         0.006694)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MVP.MVP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9552092754310793\n"
     ]
    }
   ],
   "source": [
    "print(ml.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = ml.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41572</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1732</td>\n",
       "      <td>22854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  41572   1289\n",
       "1   1732  22854"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(confusion_matrix(y_pred_val, y_test))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.969926</td>\n",
       "      <td>0.929553</td>\n",
       "      <td>0.955209</td>\n",
       "      <td>0.949740</td>\n",
       "      <td>0.955474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.960004</td>\n",
       "      <td>0.946610</td>\n",
       "      <td>0.955209</td>\n",
       "      <td>0.953307</td>\n",
       "      <td>0.955209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.964939</td>\n",
       "      <td>0.938004</td>\n",
       "      <td>0.955209</td>\n",
       "      <td>0.951472</td>\n",
       "      <td>0.955298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>43304.000000</td>\n",
       "      <td>24143.000000</td>\n",
       "      <td>0.955209</td>\n",
       "      <td>67447.000000</td>\n",
       "      <td>67447.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy     macro avg  weighted avg\n",
       "precision      0.969926      0.929553  0.955209      0.949740      0.955474\n",
       "recall         0.960004      0.946610  0.955209      0.953307      0.955209\n",
       "f1-score       0.964939      0.938004  0.955209      0.951472      0.955298\n",
       "support    43304.000000  24143.000000  0.955209  67447.000000  67447.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_report = pd.DataFrame(classification_report(y_test, y_pred_val, output_dict=True))\n",
    "class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our Random Forest Model was 93% accurate at predicting a pass being stopped.\n",
    "- EPA & closest_dist turned out to be significant features in our model.\n",
    "- Success in defending the pass truly depends on the defenders' ability to prevent separation from receiver and their reaction time.\n",
    "- When pressure is applied to the quarter back, the completion percentage significantly decreases.\n",
    "- Dime formation (6 defensive backs) had the best success in stopping the pass.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- work out mislabels and small bugs for closest_dist feature\n",
    "- use similar algorithm to find the distance of all cornerbacks to their defensive assignments i.e. WR, RB, TE, etc\n",
    "- further analyze the components of EPA to understand their influence on the model\n",
    "- explore trick plays to see if the same features carry over from the traditional offensive setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
